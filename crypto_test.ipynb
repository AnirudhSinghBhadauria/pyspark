{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6u23PoHq+KnG6ChZUQPdU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnirudhSinghBhadauria/pyspark/blob/main/crypto_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyspark.sql.types import *\n",
        "from pyspark import StorageLevel\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "jv8-vpfzUTEJ"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('crypto-test').getOrCreate()"
      ],
      "metadata": {
        "id": "yS0DVBt9Ujzw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crypto_df = (\n",
        "    spark.read.format(\"csv\")\n",
        "    .option(\"mode\", \"FAILFAST\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .option(\"skipRows\", 0)\n",
        "    .option(\"header\", \"true\")\n",
        "    .load(\"/content/crypto_tradinds.csv\")\n",
        ")\n",
        "\n",
        "remove_columns = [\n",
        "    'site_url',\n",
        "    'github_url',\n",
        "    'crypto_type',\n",
        "    'BTC_price_change_1_day',\n",
        "    'industry_name',\n",
        "    'price_btc'\n",
        "]\n",
        "\n",
        "crypto_df = crypto_df.select(\n",
        "    [column for column in crypto_df.columns if column not in remove_columns]\n",
        ")"
      ],
      "metadata": {
        "id": "h41SVP53oTkQ"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crypto_df.persist(StorageLevel.MEMORY_ONLY)"
      ],
      "metadata": {
        "id": "W339JGeHySJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crypto_df.filter(\n",
        "    col(\"ticker\") == 'ETH'\n",
        ").show()"
      ],
      "metadata": {
        "id": "Fv7hyW2Vo5XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Rolling Averages** for any crypto currency!"
      ],
      "metadata": {
        "id": "X7rSuDdExQ2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rolling_average(currency, days):\n",
        "  window = (Window.orderBy(\"trade_date\").rowsBetween(-(days), 0))\n",
        "\n",
        "  rolling_average_currency = (\n",
        "      crypto_df\n",
        "      .filter(\n",
        "          col(\"ticker\") == currency\n",
        "      )\n",
        "      .withColumn(\n",
        "          \"rolling_average\",\n",
        "          round(avg(\"price_usd\").over(window), 3)\n",
        "      )\n",
        "  )\n",
        "\n",
        "  y_value = [ravg.rolling_average for ravg in rolling_average_currency.select(\"rolling_average\").collect()]\n",
        "  x_value = [tdate.trade_date for tdate in rolling_average_currency.select(\"trade_date\").collect()]\n",
        "\n",
        "  plt.plot(x_value, y_value)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "eSIjhbSGx42W"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rolling_average(\"BTC\", 7)"
      ],
      "metadata": {
        "id": "6oerJmdCO7C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "  crypto_df\n",
        "  .select([\"ticker\", \"crypto_name\"])\n",
        "  .distinct()\n",
        "  .sample(fraction = 0.5)\n",
        "  .show(n = crypto_df.count(), truncate = False)\n",
        ")"
      ],
      "metadata": {
        "id": "HWlBHCBnPwZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_price_inr(usd_price):\n",
        "    try:\n",
        "        response = requests.get(\n",
        "            \"https://anyapi.io/api/v1/exchange/convert\",\n",
        "            params={\n",
        "                'base': 'USD',\n",
        "                'to': 'INR',\n",
        "                'amount': usd_price,\n",
        "                'apiKey': '6ht7uuqsuro70e9fpp7lioi3vnie9j5sos70fd4i6j0ooloj2q4t1j'\n",
        "            },\n",
        "            timeout=10\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        return response.json().get('converted')\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error converting price: {e}\")\n",
        "        return None\n",
        "\n",
        "def ticker():\n",
        "    coins_to_fetch = {\n",
        "        'Bitcoin', 'Ethereum', 'Solana', 'Sui',\n",
        "        'Dogecoin', 'Polygon Ecosystem Token'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\n",
        "            \"https://api.coinpaprika.com/v1/tickers/\",\n",
        "            timeout=10\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching tickers: {e}\")\n",
        "        return []\n",
        "\n",
        "    processed_coins = []\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        future_to_coin = {\n",
        "            executor.submit(process_coin, coin): coin for coin in data if coin['name'] in coins_to_fetch\n",
        "        }\n",
        "\n",
        "        for future in as_completed(future_to_coin):\n",
        "            coin = future_to_coin[future]\n",
        "            try:\n",
        "                processed_coin = future.result()\n",
        "                if processed_coin:\n",
        "                    processed_coins.append(processed_coin)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing coin {coin['name']}: {e}\")\n",
        "\n",
        "    return processed_coins\n",
        "\n",
        "def process_coin(coin):\n",
        "    processed_coin = coin.copy()\n",
        "    usd_price = coin['quotes']['USD']['price']\n",
        "    processed_coin['quotes']['INR'] = get_price_inr(usd_price)\n",
        "    return processed_coin\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    crypto_data = ticker()\n",
        "\n",
        "    crypto_extracted_df = spark.createDataFrame(crypto_data)\n",
        "    crypto_extracted_df = crypto_extracted_df.select(\n",
        "      \"name\", \"symbol\", \"rank\", \"total_supply\",\n",
        "      \"max_supply\", \"last_updated\",\n",
        "      col(\"quotes.USD.price\").alias(\"usd_price\"),\n",
        "      col(\"quotes.USD.volume_24h\").alias(\"usd_volume_24h\"),\n",
        "      col(\"quotes.USD.market_cap\").alias(\"usd_market_cap\"),\n",
        "      col(\"quotes.INR\").alias(\"inr_price\")\n",
        "    )\n",
        "\n",
        "crypto_extracted_df.show()"
      ],
      "metadata": {
        "id": "xRpxvCOYTNIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Removing **outliers**!"
      ],
      "metadata": {
        "id": "-kvLYJ3Ucl5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_outliers(df, group_col, target_col):\n",
        "    quantiles = df.groupBy(group_col).agg(\n",
        "        expr(f\"percentile_approx({target_col}, 0.25)\").alias(\"Q1\"),\n",
        "        expr(f\"percentile_approx({target_col}, 0.75)\").alias(\"Q3\")\n",
        "    )\n",
        "\n",
        "    quantiles = quantiles.withColumn(\"IQR\", col(\"Q3\") - col(\"Q1\")) \\\n",
        "                         .withColumn(\"lower_bound\", col(\"Q1\") - 1.5 * col(\"IQR\")) \\\n",
        "                         .withColumn(\"upper_bound\", col(\"Q3\") + 1.5 * col(\"IQR\"))\n",
        "\n",
        "    df_with_bounds = df.join(quantiles, on=group_col, how=\"left\")\n",
        "\n",
        "    cleaned_df = df_with_bounds.filter(\n",
        "        (col(target_col) >= col(\"lower_bound\")) &\n",
        "        (col(target_col) <= col(\"upper_bound\"))\n",
        "    ).drop(\"Q1\", \"Q3\", \"IQR\", \"lower_bound\", \"upper_bound\")\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "cleaned_crypto_df = remove_outliers(crypto_df, \"crypto_name\", \"price_usd\")\n",
        "cleaned_crypto_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD7KFTHSpbTS",
        "outputId": "2db0baeb-3223-46fa-eae1-7f5d7e48b6b0"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "431644"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    }
  ]
}